{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# CEERS: Reducing MIRI Imaging Data\n",
    "---\n",
    "**Author**: Guang Yang (gyang206265@gmail.com) \n",
    "\n",
    "**Latest Update**: 12 November 2021\n",
    "\n",
    "This notebook will reduce all available raw MIRI images through the JWST Calibration Pipeline, with some custom steps developed for our simulated data. At the end, it also tests the output photometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Imports](#imports)\n",
    "* [Notebook setup](#setup)\n",
    "* [Pipeline information](#info)\n",
    "* [The calwebb_detector1 and calwebb_image2 pipelines](#steps1&2) \n",
    "* [The calwebb_image3 pipeline](#step3) \n",
    "* [Photometry tests](#photometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell loads necessary modules \n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "from jwst import pipeline\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.associations.lib.rules_level3 import Asn_Lv3Image\n",
    "\n",
    "from glob import glob\n",
    "import sep\n",
    "from astroscrappy import detect_cosmics\n",
    "\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table\n",
    "\n",
    "from collections import defaultdict\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will reduce all raw data located in `[data_dir]/CEERS*/F*W/`, where `CEERS*` are each individual CEERS MIRI pointing, and the raw files are organized by filter (`F*W`).\n",
    "\n",
    "**Change the path for `data_dir` in the next cell to match the location of your downloaded CEERS MIRI raw images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell set the data directory and search for the raw images\n",
    "\n",
    "# Set the directory where all the data are\n",
    "#data_dir = \"./\"\n",
    "data_dir = \"/home/shared/preloaded-fits/ceers-data/miri/part1\"\n",
    "\n",
    "# Search the work directories hosting raw images\n",
    "wk_dirs = glob(f\"{data_dir}/CEERS*/*W\")\n",
    "\n",
    "#print(wk_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='info'></a>\n",
    "##  Pipeline information\n",
    "\n",
    "The cells below will run the [JWST Calibration Pipeline](https://github.com/spacetelescope/jwst). \n",
    "We briefly summarize the pipeline below, and more details can be found in the [User Manual](https://jwst-pipeline.readthedocs.io/en/latest/index.html#user-manual).\n",
    "\n",
    "The inputs are raw MIRI images and the outputs are calibrated science images, weight images, and catalogs (optional; see below).  \n",
    "\n",
    "The pipeline has three stages: \n",
    "* [Stage 1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) applies basic detector-level corrections, yielding a count-rate map for each exposure.\n",
    "* [Stage 2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html#calwebb-image2) applies additional instrumental corrections and calibrations that result in a fully calibrated individual exposure.  \n",
    "* [Stage 3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html) combines the calibrated multiple exposures into a single rectified image and perform source detections (if desired). \n",
    "\n",
    "Below, we adopt the default settings for Stages 1 & 2 (except skipping a function in Stage 1; see below), but significantly modify Stage 3. The reason is that Stage 3 is still under intensive development and the current default settings cannot produce optimal results for our simulated data (see [Yang et al. 2021](https://ui.adsabs.harvard.edu/abs/2021ApJ...908..144Y/abstract) for details). Also, our MIRISIM-simulated raw data do not contain the physical WCS information, and we need to correct the WCS on our own at Stage 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='steps1&2'></a>\n",
    "## The calwebb-detector1 and calwebb_image2 pipelines\n",
    "\n",
    "Converting ramps to slopes ([*calwebb_detector1*, Detector1Pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)) and producing calibrated slope images ([*calwebb_image2*, Image2Pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_image2.html)). \n",
    "\n",
    "We will call the pipeline using the [`run()` method](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/call_via_run.html).\n",
    "\n",
    "This cell will take several minutes to run, depending on how many raw images you are reducing. The Stage 1 reduction pipeline steps in particular can take a while for each input raw image.\n",
    "\n",
    "Note: We skip the \"refpix\" function in Stage 1, because MIRISIM dose not put in the targeted noise of this function and running it would cause stripe-like artifacts in the final science images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 21:58:48,667 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n",
      "2022-01-24 21:58:48,669 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2022-01-24 21:58:48,671 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2022-01-24 21:58:48,673 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2022-01-24 21:58:48,675 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2022-01-24 21:58:48,676 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2022-01-24 21:58:48,678 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2022-01-24 21:58:48,679 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2022-01-24 21:58:48,681 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2022-01-24 21:58:48,682 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2022-01-24 21:58:48,683 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2022-01-24 21:58:48,685 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2022-01-24 21:58:48,686 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2022-01-24 21:58:48,687 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2022-01-24 21:58:48,689 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2022-01-24 21:58:48,691 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2022-01-24 21:58:48,692 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n",
      "2022-01-24 21:58:48,705 - stpipe.Detector1Pipeline - INFO - Detector1Pipeline instance created.\n",
      "2022-01-24 21:58:48,706 - stpipe.Detector1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2022-01-24 21:58:48,708 - stpipe.Detector1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2022-01-24 21:58:48,710 - stpipe.Detector1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2022-01-24 21:58:48,711 - stpipe.Detector1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2022-01-24 21:58:48,712 - stpipe.Detector1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2022-01-24 21:58:48,714 - stpipe.Detector1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2022-01-24 21:58:48,715 - stpipe.Detector1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2022-01-24 21:58:48,716 - stpipe.Detector1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2022-01-24 21:58:48,717 - stpipe.Detector1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2022-01-24 21:58:48,720 - stpipe.Detector1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2022-01-24 21:58:48,722 - stpipe.Detector1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2022-01-24 21:58:48,723 - stpipe.Detector1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2022-01-24 21:58:48,725 - stpipe.Detector1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2022-01-24 21:58:48,726 - stpipe.Detector1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2022-01-24 21:58:48,728 - stpipe.Detector1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2022-01-24 21:58:48,730 - stpipe.Detector1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n"
     ]
    }
   ],
   "source": [
    "# This cell performs stages 1 & 2 reduction\n",
    "\n",
    "# Iterater over each band\n",
    "for wk_dir in wk_dirs:\n",
    "    # Search for raw files \n",
    "    raw_files = glob(wk_dir+'*exp?.fits')\n",
    "    # The list to save the path of stage1 products \n",
    "    stage1_files = []\n",
    "    # Iterate over the input\n",
    "    det1 = Detector1Pipeline()\n",
    "    # Skip the refpix function\n",
    "    det1.refpix.skip = True\n",
    "    for file in raw_files:\n",
    "        # Run the pipeline\n",
    "        result = det1.run(file)\n",
    "        # Generate the file name of stage1 product\n",
    "        stage1_file = file[:file.rfind('.fits')] + '_stage1.fits'\n",
    "        # Save the stage1 products to file\n",
    "        result.save(stage1_file)\n",
    "        # Save the file name\n",
    "        stage1_files.append(stage1_file)\n",
    "\n",
    "    # Process to stage 2\n",
    "    stage1_files = glob(wk_dir+'*stage1*.fits')\n",
    "    stage2_files = []\n",
    "    # Iterate over the input\n",
    "    for file in stage1_files:\n",
    "        # Run the pipeline\n",
    "        img2 = Image2Pipeline()\n",
    "        result = img2.run(file)\n",
    "        # Generate the file name of stage2 product\n",
    "        stage2_file = file[:file.rfind('stage1.fits')] + 'stage2.fits'\n",
    "        # Save the results to file\n",
    "        result[0].save(stage2_file)\n",
    "        # Save the file name\n",
    "        stage2_files.append(stage2_file)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## The calwebb_image3 pipeline\n",
    "\n",
    "Ensemble calibrations ([*calwebb_image3*, Image3Pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_image3.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 21:58:54,541 - stpipe.Image3Pipeline - INFO - Image3Pipeline instance created.\n",
      "2022-01-24 21:58:54,543 - stpipe.Image3Pipeline.assign_mtwcs - INFO - AssignMTWcsStep instance created.\n",
      "2022-01-24 21:58:54,545 - stpipe.Image3Pipeline.tweakreg - INFO - TweakRegStep instance created.\n",
      "2022-01-24 21:58:54,547 - stpipe.Image3Pipeline.skymatch - INFO - SkyMatchStep instance created.\n",
      "2022-01-24 21:58:54,549 - stpipe.Image3Pipeline.outlier_detection - INFO - OutlierDetectionStep instance created.\n",
      "2022-01-24 21:58:54,550 - stpipe.Image3Pipeline.resample - INFO - ResampleStep instance created.\n",
      "2022-01-24 21:58:54,552 - stpipe.Image3Pipeline.source_catalog - INFO - SourceCatalogStep instance created.\n",
      "2022-01-24 21:58:54,679 - stpipe.Image3Pipeline.skymatch - INFO - Step skymatch running with args ({'asn_type': 'image3', 'asn_rule': 'Asn_Lv3Image', 'version_id': None, 'code_version': '1.3.3', 'degraded_status': 'No known degraded exposures in association.', 'program': 'noprogram', 'constraints': 'No constraints', 'asn_id': '', 'target': 'none', 'asn_pool': 'none', 'products': [{'name': 'l3_results', 'members': []}]},).\n",
      "2022-01-24 21:58:54,681 - stpipe.Image3Pipeline.skymatch - INFO - Step skymatch parameters are: {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'skymethod': 'global+match', 'match_down': True, 'subtract': False, 'stepsize': None, 'skystat': 'mode', 'dqbits': '0', 'lower': None, 'upper': None, 'nclip': 5, 'lsigma': 4.0, 'usigma': 4.0, 'binwidth': 0.1}\n",
      "2022-01-24 21:58:54,688 - stpipe.Image3Pipeline.skymatch - INFO -  \n",
      "2022-01-24 21:58:54,688 - stpipe.Image3Pipeline.skymatch - INFO - ***** jwst.skymatch.skymatch.match() started on 2022-01-24 21:58:54.688077\n",
      "2022-01-24 21:58:54,689 - stpipe.Image3Pipeline.skymatch - INFO -  \n",
      "2022-01-24 21:58:54,689 - stpipe.Image3Pipeline.skymatch - INFO - Sky computation method: 'global+match'\n",
      "2022-01-24 21:58:54,690 - stpipe.Image3Pipeline.skymatch - INFO - Sky matching direction: DOWN\n",
      "2022-01-24 21:58:54,690 - stpipe.Image3Pipeline.skymatch - INFO - Sky subtraction from image data: OFF\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument 'images' must contain at least one image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m img3\u001b[38;5;241m.\u001b[39mresample\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m wk_dir\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# *** GREG *** - this causes an error\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m res_step3 \u001b[38;5;241m=\u001b[39m \u001b[43mimg3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskymatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Subtract the position-dependent backgrounds\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res_step3\u001b[38;5;241m.\u001b[39m_models)):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Extract the data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/stpipe/step.py:430\u001b[0m, in \u001b[0;36mStep.run\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     step_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess() takes exactly\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/jwst/skymatch/skymatch_step.py:96\u001b[0m, in \u001b[0;36mSkyMatchStep.process\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogical error in the pipeline code.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# match/compute sky values:\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;43;01mmatch\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskymethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskymethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_down\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_down\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubtract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# set sky background value in each image's meta:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m images:\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/jwst/skymatch/skymatch.py:272\u001b[0m, in \u001b[0;36mmatch\u001b[0;34m(images, skymethod, match_down, subtract)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach element of the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be either a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkyImage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkyGroup\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nimages \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must contain at least one image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of images to be sky-subtracted and/or matched: \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(nimages)\n\u001b[1;32m    277\u001b[0m )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Print conversion factors\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument 'images' must contain at least one image"
     ]
    }
   ],
   "source": [
    "# This cell performs Stage 3 reduction, \n",
    "# correct for WCS (only needed for simulated images), and \n",
    "# perform photometry  \n",
    "\n",
    "# Set below to True if you want the pipeline to extract photometry using photutils\n",
    "photo_flag = True\n",
    "\n",
    "# Set the background configurations\n",
    "bkg_cell_size = 16\n",
    "bkg_filt_size = 3\n",
    "fthresh = -99\n",
    "\n",
    "# The correction factors for different bands \n",
    "# These are obtained by simulating bright point-like sources\n",
    "# (see Appendix A of Yang+2021)\n",
    "cor_facs = {\"F560W\":1.069, \n",
    "            \"F770W\":1.156, \n",
    "            \"F1000W\":1.040, \n",
    "            \"F1280W\":0.998, \n",
    "            \"F1500W\":1.062, \n",
    "            \"F1800W\":0.973, \n",
    "            \"F2100W\":1.047}\n",
    "\n",
    "# CR maps (produced by gen_cr_map.ipynb) needed below\n",
    "for wk_dir in wk_dirs:\n",
    "    # Process to stage 3\n",
    "    stage2_files = sorted( glob(wk_dir+'*stage2.fits') )\n",
    "    # Create an association \n",
    "    asn = dict( asn_from_list.asn_from_list(stage2_files, rule=Asn_Lv3Image, product_name='l3_results') )\n",
    "    asn[\"asn_type\"] = \"image3\"\n",
    "    asn[\"asn_id\"] = \"\"\n",
    "    # Configure the stage 3 pipeline \n",
    "    img3 = Image3Pipeline()\n",
    "    img3.output_dir = wk_dir\n",
    "    img3.output_file = 'stage3_merged_image'\n",
    "    img3.resample.save_results = False\n",
    "    img3.resample.output_dir = wk_dir\n",
    "\n",
    "    # Run the pipeline\n",
    "    # *** GREG *** - this causes an error\n",
    "    res_step3 = img3.skymatch.run(asn)\n",
    "        \n",
    "    # Subtract the position-dependent backgrounds\n",
    "    for seq_idx in range(len(res_step3._models)):\n",
    "        # Extract the data\n",
    "        sci_img = np.array(res_step3._models[seq_idx].data)\n",
    "        dq_img = np.array(res_step3._models[seq_idx].dq)\n",
    "        err_img = np.array(res_step3._models[seq_idx].err)\n",
    "        bkg_level = res_step3._models[seq_idx].meta.background.level\n",
    "        # Mask bad pixels\n",
    "        mask = (dq_img>100)\n",
    "        mask[sci_img < bkg_level/2] = True\n",
    "\n",
    "        # Also mask the nearby pixels\n",
    "        bad_idxs = np.where(mask)\n",
    "        # To avoid index underflow\n",
    "        use_Sidxs = np.where( bad_idxs[0]!=0 )\n",
    "        mask[bad_idxs[0][use_Sidxs]-1, bad_idxs[1][use_Sidxs]] = True\n",
    "        use_Sidxs = np.where( bad_idxs[1]!=0 )\n",
    "        mask[bad_idxs[0][use_Sidxs], bad_idxs[1][use_Sidxs]-1] = True\n",
    "        # To avoid index overflow \n",
    "        use_Sidxs = np.where( bad_idxs[0]!=sci_img.shape[0]-1 )\n",
    "        mask[bad_idxs[0][use_Sidxs]+1, bad_idxs[1][use_Sidxs]] = True\n",
    "        use_Sidxs = np.where( bad_idxs[1]!=sci_img.shape[1]-1 )\n",
    "        mask[bad_idxs[0][use_Sidxs], bad_idxs[1][use_Sidxs]+1] = True\n",
    "        \n",
    "        # Mask coronograph\n",
    "        mask[:, :350] = True\n",
    "        # Estimate background\n",
    "        bkg = sep.Background(sci_img.byteswap().newbyteorder(), \n",
    "                             bw=bkg_cell_size, bh=bkg_cell_size, \n",
    "                             fw=bkg_filt_size, fh=bkg_filt_size, mask=mask, fthresh=fthresh)\n",
    "        # Subtract background\n",
    "        sci_img -= bkg.back()\n",
    "        # Re-set the metadata, indicating background already subtracted\n",
    "        res_step3._models[seq_idx].meta.background.subtracted = True\n",
    "        # Mask defect pixels\n",
    "        mask[sci_img < -10*err_img] = True\n",
    "        # Mask the CR \n",
    "        cr_map = detect_cosmics(sci_img, sigclip=1)[0]*1        \n",
    "        mask[np.where(cr_map)] = True\n",
    "        \n",
    "        # Set masked region to zero\n",
    "        sci_img[mask] = 0\n",
    "        # Update the data\n",
    "        res_step3._models[seq_idx].data = sci_img\n",
    "        # Update dq\n",
    "        res_step3._models[seq_idx].dq[mask] = np.max(res_step3._models[seq_idx].dq)     \n",
    "\n",
    "    # Merge the exposures\n",
    "    res_step4 = img3.resample.run(res_step3)\n",
    "    mask = res_step4.wht==0\n",
    "    # subtract the background\n",
    "    bkg = sep.Background(res_step4.data, \n",
    "                         bw=bkg_cell_size, bh=bkg_cell_size, \n",
    "                         fw=bkg_filt_size, fh=bkg_filt_size, mask=mask, fthresh=fthresh)\n",
    "    res_step4.data -= bkg.back()\n",
    "    res_step4.data[mask] = 0\n",
    "    res_step4.save(wk_dir+'stage3_merged_image_resample.fits')  \n",
    "    \n",
    "    # Updte WCS and output final science and weight images\n",
    "    # Read mirisim products\n",
    "    mirisim_data = fits.open(wk_dir+'stage3_merged_image_resample.fits')[1]\n",
    "    hd = mirisim_data.header\n",
    "    # Extract the old wcs info.\n",
    "    old_wcs = WCS(hd)\n",
    "\n",
    "    # Read the pointing info.\n",
    "    pt_id = wk_dir[wk_dir.find('CEERS')+5:wk_dir.find('CEERS')+7]\n",
    "    if pt_id[1]=='/': pt_id=pt_id[0]\n",
    "    reg_data = Table.read(data_dir+\"pointing_info/miri%s_reg.fits\" %pt_id)[0]\n",
    "    # Get the new reference pixel\n",
    "    new_crpix_1, new_crpix_2 = old_wcs.all_world2pix([0], [0], 1)\n",
    "    new_crpix_1, new_crpix_2 = new_crpix_1[0], new_crpix_2[0]\n",
    "    # Re-set the ra-dec for the new pix ref\n",
    "    new_crval_1, new_crval_2 = reg_data['RA_Ref'], reg_data['DEC_Ref']\n",
    "    # Update the rotation matrix\n",
    "    theta = reg_data['angle']*np.pi/180 + np.arcsin(mirisim_data.header['PC1_2'])\n",
    "    new_pc1_1, new_pc1_2 = -np.cos(theta), np.sin(theta)\n",
    "    new_pc2_1, new_pc2_2 =  np.sin(theta), np.cos(theta)\n",
    "    # Fill in the new WCS and write to file\n",
    "    mirisim_data.header['CRPIX1'] = new_crpix_1\n",
    "    mirisim_data.header['CRPIX2'] = new_crpix_2\n",
    "    mirisim_data.header['CRVAL1'] = new_crval_1\n",
    "    mirisim_data.header['CRVAL2'] = new_crval_2\n",
    "    mirisim_data.header['PC1_1'] = new_pc1_1\n",
    "    mirisim_data.header['PC1_2'] = new_pc1_2\n",
    "    mirisim_data.header['PC2_1'] = new_pc2_1\n",
    "    mirisim_data.header['PC2_2'] = new_pc2_2\n",
    "        \n",
    "    # Apply corrections \n",
    "    filt = wk_dir[wk_dir.find('F'):wk_dir.find('W')+1]\n",
    "    mirisim_data.data *= cor_facs[filt]\n",
    "    # Write to file\n",
    "    fits.writeto(wk_dir+'final_image.fits', mirisim_data.data, \n",
    "                 header=mirisim_data.header, overwrite=True)\n",
    "    # Write the weight image\n",
    "    wht_data = fits.open(wk_dir+'stage3_merged_image_resample.fits')[3]\n",
    "    fits.writeto(wk_dir+'final_weight.fits', wht_data.data, \n",
    "                 header=mirisim_data.header, overwrite=True)\n",
    "    \n",
    "    # Extract photometry (if needed)\n",
    "    if photo_flag:\n",
    "        # Do not save results immediately, as we need to correct WCS\n",
    "        img3.source_catalog.save_results = False\n",
    "        # Perform source detection and photometry extraction \n",
    "        # Parameters can be changed by img3.source_catalog.update_pars\n",
    "        # Use img3.source_catalog.get_pars to display current parameters\n",
    "        res_step5 = img3.source_catalog.run(res_step4)\n",
    "        # Correct for WCS\n",
    "        # Read the corrected WCS\n",
    "        cor_wcs = WCS(mirisim_data.header)\n",
    "        # Transform x,y to ra,dec\n",
    "        ras, decs = cor_wcs.all_pix2world(res_step5['xcentroid'], res_step5['ycentroid'], 0)\n",
    "        # Update ra,dec in res_step5 \n",
    "        for src_idx, _ in enumerate(res_step5):\n",
    "            res_step5['sky_centroid'][src_idx] = \\\n",
    "                SkyCoord(ras[src_idx],decs[src_idx], unit='deg')\n",
    "        # Save the catalog to file\n",
    "        res_step5.write(wk_dir+'photutils_catalog.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='photometry'></a>\n",
    "## Photometry tests\n",
    "\n",
    "The cells below are an example test, i.e., measured photometry vs. model-input photometry. This example test shows apparent magnitude offsets. This is expected, because the photutils is not fine-tuned when performing photometry (see above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell define a function to match between two catalogs \n",
    "\n",
    "def match(ra1, de1, ra2, de2, rad, opt = 2, silent=False):\n",
    "    '''\n",
    "    This function will perform one-one match between two catalogs\n",
    "    \n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, should be array-like unit: deg\n",
    "        rad: matching radius, unit: arcsec\n",
    "\n",
    "    Keywords:\n",
    "        opt: same as srcor.pro in IDL\n",
    "                0, source in catalog 2 may correspond to >1 sources in catalog 1\n",
    "                1, forced 1-1 match \n",
    "                2, forced 1-1 match, but the program will run two times. At the first run is to obtain the \n",
    "                   median coordinate offset between the two catalogs. Then we apply the offset to\n",
    "                   one catalog to eliminate the systematic difference. The second run is based on the\n",
    "                   updated coordinates. (default) \n",
    "        silent: True, do not display results for opt=0 or 1\n",
    "                False, display results (default)\n",
    "\n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: arcsec \n",
    "    '''\n",
    "\n",
    "    # Format unification\n",
    "    ra1 = np.array(ra1)\n",
    "    de1 = np.array(de1)\n",
    "    ra2 = np.array(ra2)\n",
    "    de2 = np.array(de2)\n",
    "\n",
    "    # Check if all RA, DEC are float\n",
    "    if ( np.where(np.isfinite(ra1))[0].size != ra1.size ) | \\\n",
    "       ( np.where(np.isfinite(de1))[0].size != de1.size ) | \\\n",
    "       ( np.where(np.isfinite(ra2))[0].size != ra2.size ) | \\\n",
    "       ( np.where(np.isfinite(de2))[0].size != de2.size ) : \\\n",
    "        sys.exit('Error: non-float in ra,dec')\n",
    "\n",
    "    if ra1.shape != de1.shape:\n",
    "        raise ValueError('ra1 and dec1 do not match!')\n",
    "    if ra2.shape != de2.shape:\n",
    "        raise ValueError('ra2 and dec2 do not match!')\n",
    "\n",
    "    # Initial match, note that id_2 may contain repetitive elements\n",
    "    if opt == 0:\n",
    "        id1, id2, dis = _ini_match(ra1, de1, ra2, de2, rad/3600.)\n",
    "        if not(silent):\n",
    "            print('Multi-one match: ', len(id1), ' sources')\n",
    "        return id1, id2, dis*3600.\n",
    "\n",
    "    # First match, only the nearest neighbor is left when multi-to-one occurs\n",
    "    id1, id2, dis = _1st_match(ra1, de1, ra2, de2, rad/3600.)\n",
    "    if opt == 1:\n",
    "        if not(silent):\n",
    "            print('Forced one-one match: ', len(id1), ' sources')\n",
    "        return id1, id2, dis*3600.\n",
    "    print('First match: ', len(id1), ' sources')\n",
    "\n",
    "    # Second match, elliminate the offset\n",
    "    print( 'RA offset:', \\\n",
    "           np.median(ra1[id1] - ra2[id2]) * 3600 \\\n",
    "           * math.cos(np.deg2rad(np.median(de1))), 'arcsec', \\\n",
    "           'DEC offset:', \\\n",
    "           np.median(de1[id1] - de2[id2])*3600, 'arcsec')\n",
    "    ra2_new = ra2 + np.median(ra1[id1] - ra2[id2])\n",
    "    de2_new = de2 + np.median(de1[id1] - de2[id2])\n",
    "    id1, id2, dis = _1st_match(ra1, de1, ra2_new, de2_new, rad/3600.)\n",
    "    print('Second match: ', len(id1), ' sources')\n",
    "\n",
    "    return id1, id2, dis*3600\n",
    "            \n",
    "\n",
    "def _1st_match(ra1, de1, ra2, de2, rad):\n",
    "    '''\n",
    "    This function performs the forced 1-1 match. Similar to srcor.pro (opt=1) in IDL.\n",
    "    \n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, unit: deg\n",
    "        rad: matching radius, unit: deg\n",
    "    \n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: deg \n",
    "    '''\n",
    "\n",
    "    # Initial match, might produce multi-one match\n",
    "    id1, id2, dis = _ini_match(ra1, de1, ra2, de2, rad)\n",
    "\n",
    "    # Find the repetitive ones  (routine)\n",
    "    rep = defaultdict(list)\n",
    "    for i, item in enumerate(id2):\n",
    "        rep[item].append(i)\n",
    "    rep = {k:v for k,v in rep.items() if len(v) > 1}\n",
    "    # note that k is indexes in catalog II, v is indexes in the matching array\n",
    "\n",
    "    # For them, reserve the nearest one only\n",
    "    kill = []\n",
    "    for dum, idx in rep.items(): \n",
    "        dis_rep = dis[idx] # Their distances \n",
    "        best = dis_rep.argmin()  # Pick up the nearest one\n",
    "        kill.append(np.delete(idx, best)) # Creat the to-be-delete list\n",
    "\n",
    "    buf = np.arange(0) # Transform format from list to numpy array\n",
    "    while kill != []: \n",
    "        buf = np.append(buf, kill.pop())\n",
    "    kill = buf\n",
    "        \n",
    "    id1 = np.delete(id1, kill) # Remove them\n",
    "    id2 = np.delete(id2, kill)\n",
    "    dis = np.delete(dis, kill) \n",
    "\n",
    "    return id1, id2, dis\n",
    "\n",
    "\n",
    "def _ini_match(ra1, de1, ra2, de2, rad):\n",
    "    '''\n",
    "    This function is modified from pyspherematch.py, available at\n",
    "    https://gist.github.com/eteq/4599814\n",
    "    The main change is, turn to match_coordinates_sky (astropy) from KDTree (scipy).\n",
    "    Because the second is based on 'straight-line' distance rather than \n",
    "    'great-circle' distance.\n",
    "\n",
    "    Inputs: \n",
    "        ra1, de1, ra2, de2: coordiantes in two catalogs, unit: deg\n",
    "        rad: matching radius, unit: deg\n",
    "    \n",
    "    Outputs:\n",
    "        id1, indexes of matched sources in catalog I \n",
    "        id2, indexes of matched sources in catalog II\n",
    "        dis, distances of the pairs, unit: deg \n",
    "    '''\n",
    "\n",
    "    cor1 = SkyCoord(ra=ra1*u.deg, dec=de1*u.deg, frame='icrs') # Change to ICRS system\n",
    "    cor2 = SkyCoord(ra=ra2*u.deg, dec=de2*u.deg, frame='icrs')\n",
    "\n",
    "    id2, dis, buf = cor1.match_to_catalog_sky(cor2) # Match\n",
    "    dis = np.array(dis) # Drop the unit\n",
    "    id1 = np.arange(ra1.size)\n",
    "    if id2.size<=1:\n",
    "        id2 = np.array([id2])\n",
    "    else:\n",
    "        id2 = np.array(id2)\n",
    "\n",
    "    msk = dis < rad\t # Filter out those with distance > rad\n",
    "    id1 = id1[msk]\n",
    "    id2 = id2[msk]\n",
    "    dis = dis[msk]\n",
    "\n",
    "    return id1, id2, dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will compare the input and measure photometry for a given CEERS MIRI pointing and band. \n",
    "\n",
    "**Set the pointing ID and band you want to compare in the first two lines (`pt_id` and `band`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/shared/preloaded-fits/ceers-data/miri/part1/CEERS7b/F770W/photutils_catalog.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Read the input the measured photometry\u001b[39;00m\n\u001b[1;32m      8\u001b[0m input_cat \u001b[38;5;241m=\u001b[39m Table\u001b[38;5;241m.\u001b[39mread(data_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model_cat/miri\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_src_sam.fits\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39mpt_id)\n\u001b[0;32m----> 9\u001b[0m meas_cat \u001b[38;5;241m=\u001b[39m \u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/CEERS\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/photutils_catalog.fits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpt_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Extract ra & dec from photutils results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m phot_ras, phot_decs \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/astropy/table/connect.py:62\u001b[0m, in \u001b[0;36mTableRead.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m units \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m descriptions \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescriptions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# For some readers (e.g., ascii.ecsv), the returned `out` class is not\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# guaranteed to be the same as the desired output `cls`.  If so,\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# try coercing to desired class without copying (io.registry.read\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# would normally do a copy).  The normal case here is swapping\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Table <=> QTable.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/astropy/io/registry/core.py:184\u001b[0m, in \u001b[0;36mUnifiedInputRegistry.read\u001b[0;34m(self, cls, format, cache, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m get_readable_fileobj(args[\u001b[38;5;241m0\u001b[39m], encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, cache\u001b[38;5;241m=\u001b[39mcache)\n\u001b[0;32m--> 184\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/jwebbinar/lib/python3.8/site-packages/astropy/utils/data.py:271\u001b[0m, in \u001b[0;36mget_readable_fileobj\u001b[0;34m(name_or_obj, encoding, cache, show_progress, remote_timeout, sources, http_headers)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_url:\n\u001b[1;32m    267\u001b[0m     name_or_obj \u001b[38;5;241m=\u001b[39m download_file(\n\u001b[1;32m    268\u001b[0m         name_or_obj, cache\u001b[38;5;241m=\u001b[39mcache, show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[1;32m    269\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mremote_timeout, sources\u001b[38;5;241m=\u001b[39msources,\n\u001b[1;32m    270\u001b[0m         http_headers\u001b[38;5;241m=\u001b[39mhttp_headers)\n\u001b[0;32m--> 271\u001b[0m fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_url \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache:\n\u001b[1;32m    273\u001b[0m     delete_fds\u001b[38;5;241m.\u001b[39mappend(fileobj)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/shared/preloaded-fits/ceers-data/miri/part1/CEERS7b/F770W/photutils_catalog.fits'"
     ]
    }
   ],
   "source": [
    "# This cell makes a plot comparing measured vs. input photometry\n",
    "\n",
    "# Set the pointing ID and the band you want to compare \n",
    "pt_id = '7b'\n",
    "band = 'F770W'\n",
    "\n",
    "# Read the input the measured photometry\n",
    "input_cat = Table.read(data_dir+'/model_cat/miri%s_src_sam.fits' %pt_id)\n",
    "meas_cat = Table.read(data_dir+'/CEERS%s/%s/photutils_catalog.fits' %(pt_id, band))\n",
    "\n",
    "# Extract ra & dec from photutils results\n",
    "phot_ras, phot_decs = [], []\n",
    "for row in meas_cat:\n",
    "    phot_ras.append(row['sky_centroid'].ra.deg)\n",
    "    phot_decs.append(row['sky_centroid'].dec.deg)\n",
    "# Match photutils and input sources \n",
    "input_phot_idxs, phot_input_idxs, ds = match(input_cat['ra'], input_cat['dec'], phot_ras, phot_decs, 1, opt=2)\n",
    "# Compare the magnitude \n",
    "input_mags = -2.5*np.log10(input_cat[input_phot_idxs][band])+23.9\n",
    "phot_mags = meas_cat['aper_total_abmag'][phot_input_idxs]\n",
    "# Plot mag. vs. mag\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.subplot(211)\n",
    "plt.plot(input_mags, phot_mags, 'ko', alpha=0.5)\n",
    "plt.plot(range(31),'C3')\n",
    "plt.xlim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "plt.ylim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "#plt.xlim(20, 26)\n",
    "#plt.ylim(20, 26)\n",
    "plt.xlabel('model mag')\n",
    "plt.ylabel('photutils mag')\n",
    "# Plot det_mag vs. mag\n",
    "plt.subplot(212)\n",
    "plt.plot(input_mags, phot_mags-input_mags, 'ko', alpha=0.5)\n",
    "plt.plot([0,30],[0,0],'C3')\n",
    "plt.xlim(np.min(input_mags)*0.95, np.max(input_mags)*1.05)\n",
    "#plt.xlim(20, 26)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlabel('model mag')\n",
    "plt.ylabel(r'$\\Delta$mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWebbinar",
   "language": "python",
   "name": "jwebbinar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
